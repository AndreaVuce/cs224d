% Template LaTeX source file for homework problem solutions.
% Alan T. Sherman (9/9/98)
% Updated: Greg King (2014)

% Running LaTeX
%
% Name this file FOO.tex
% latex FOO
% latex FOO   
%    (You have to run latex twice to get the cross references correct.
%     Running latex creates a file FOO.dvi 
%     You can view dvi files with the program xdvi )
% xdvi FOO.dvi &
%
% lpr -d FOO.dvi
%    (To print the dvi file.   Be sure to use the "-d" print option,
%     and be sure your printer can handle dvi files (not all printers can).
%     Do NOT print with "lpr FOO.dvi", which will print tens of pages
%     of unreadable dvi source code. Printing a postscript (ps) file
%     is usually more reliable, as explained below.)
%
% dvips FOO.dvi
%    (To create a postscript file named FOO.ps 
%     which you can view with the program ghostview )
% ghostview FOO.ps &
% lpr FOO.ps
%    (To print the ps file.)

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[letter,12pt]{article}

\RequirePackage{amsmath}
\RequirePackage{amsmath,amssymb,amsthm}
\RequirePackage{tikz}
\usepackage{listings}
\usepackage{color}
\usepackage{textcomp}
\usepackage{graphicx}

\renewcommand{\lstlistlistingname}{Code Listings} 
\renewcommand{\lstlistingname}{Code Listing} 
\definecolor{gray}{gray}{0.5} 
\definecolor{key}{rgb}{0,0.5,0} 
\lstnewenvironment{python}[1][]{ 
\lstset{
language=python,
basicstyle=\ttfamily\small,
otherkeywords={1, 2, 3, 4, 5, 6, 7, 8 ,9 , 0, -, =, +, [, ], (, ), \{, \}, :, *, !},
keywordstyle=\color{blue},
stringstyle=\color{red},
showstringspaces=false,
emph={class, pass, in, for, while, if, is, elif, else, not, and, or,
def, print, exec, break, continue, return},
emphstyle=\color{black}\bfseries,
emph={[2]True, False, None, self},
emphstyle=[2]\color{key},
emph={[3]from, import, as},
emphstyle=[3]\color{blue},
upquote=true,
morecomment=[s]{"""}{"""},
commentstyle=\color{gray}\slshape,
frame=tb,
rulesepcolor=\color{blue},#1
}}{}


\usetikzlibrary{calc}
\RequirePackage{tkz-euclide}
\usetkzobj{all}

\setlength{\textheight}{8.5in}
\setlength{\headheight}{.25in}
\setlength{\headsep}{.25in}
\setlength{\topmargin}{0in}
\setlength{\textwidth}{6.5in}
\setlength{\oddsidemargin}{0in}
\setlength{\evensidemargin}{0in}

\newcommand{\myN}{\hbox{N\hspace*{-.9em}I\hspace*{.4em}}}
\newcommand{\myZ}{\hbox{Z}^+}
\newcommand{\myR}{\hbox{R}}

\newcommand{\myfunction}[3]
{${#1} : {#2} \rightarrow {#3}$ }

\newcommand{\myzrfunction}[1]
{\myfunction{#1}{{\myZ}}{{\myR}}}


% Formating Macros
%

\newcommand{\myheader}[4]
{\vspace*{-0.5in}
\noindent
{#1} \hfill {#3}

\noindent
{#2} \hfill {#4}

\noindent
\rule[8pt]{\textwidth}{1pt}

\vspace{1ex} 
}  % end \myheader 

\newcommand{\myalgsheader}[0]
{\myheader{Stanford University, Department of Computer Science}
{Computer Science 224D}{Spring 2016}{Section 1}}

% Running head (goes at top of each page, beginning with page 2.
% Must precede by \pagestyle{myheadings}.
\newcommand{\myrunninghead}[2]
{\markright{{\it {#1}, {#2}}}}

\newcommand{\myrunningalgshead}[2]
{\myrunninghead{Computer Science 224D}{{#1}}}

\newcommand{\myrunninghwhead}[2]
{\myrunningalgshead{Solution to Assignment {#1}, Problem {#2}}}

\newcommand{\mytitle}[1]
{\begin{center}
{\large {\bf {#1}}}
\end{center}}

\newcommand{\myhwtitle}[3]
{\begin{center}
{\large {\bf Solution to Assignment {#1}, Problem {#2}}}\\
\medskip 
{\it {#3}} % Name goes here
\end{center}}

\newcommand{\mysection}[1]
{\noindent {\bf {#1}}}

%%%%%% Begin document with header and title %%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}

\myalgsheader

\pagestyle{plain}
\setcounter{page}{1}
\myhwtitle{1}{1(a)}{Gregory King}

\bigskip

\noindent {\bf Softmax} Prove that softmax (denoted $\textrm{softmax}({\bf x})$)
is invariant to a constant offset in the input, that is, for any input vector
$\bf x$ and any constant $c$,
\begin{equation}
\textrm{softmax}({\bf x}) = \textrm{softmax}({\bf x} + c),
\end{equation}
where $({\bf x} + c)$ means adding the constant $c$ to every dimension of ${\bf x}$.

{\bf Note}: In practice, we make use of this property and choose $c = -\textrm{max}_{i}({\bf x_i})$, when computing $\textrm{softmax}$ probabilities for numerical stability (i.e. subtracting the maximum element from all elements of ${\bf x}$).\vspace{5mm}

\noindent\rule{\textwidth}{0.4pt}\vspace{5mm}

\noindent Starting from the definition of softmax,
\begin{equation}
\textrm{softmax}({\bf x})_{i} = \frac{e^{x_{i}}}{\sum_{j=1}{e^{x_{j}}}}
\end{equation}
it follows, the linear shift, ${\bf x} + c$, yields the following (for the $i$ element):
\begin{align}
\textrm{softmax}({\bf x} + c)_{i} & = \frac{e^{(x_{i} + c)}}{\sum_{j=1}{e^{(x_{j} + c)}}}\\
                                                 & = \frac{e^{c}}{e^{c}}\frac{e^{(x_{i})}}{\sum_{j=1}{e^{(x_{j})}}}\\
                                                 & = \textrm{softmax}({\bf x})_{i}
\end{align}
since this is true for an arbitary $i$, it follows immediately that the linear shift has no affect on the softmax probabilities.


\clearpage
\pagestyle{myheadings}
\myrunninghwhead{1}{1 (Softmax)}

\myhwtitle{1}{1(b)}{Gregory King}

\bigskip

\noindent Given an input matrix of \texttt{N}-rows and \texttt{d}-columns, compute the softmax prediction for each row.
Write your implementation in \texttt{q1\_softmax.py}. You may test by executing python \texttt{q1\_softmax.py}.\\

\noindent \textbf{Note:} The provided tests are not exhaustive. Later parts of the assignment will reference this code so it is
important to have a correct implementation. Your implementation should also be efficient and vectorized
whenever possible. A non-vectorized implementation will not receive full credit!\vspace{5mm}

\noindent\rule{\textwidth}{0.4pt}
\begin{python}
import numpy as np

def softmax(x):
    c = np.max(x, axis=x.ndim - 1, keepdims=True)
    #for numerical stability
    y = np.sum(np.exp(x - c), axis=x.ndim - 1, keepdims=True)
    x = np.exp(x - c)/y
    return x
\end{python}
\clearpage

\myrunninghwhead{1}{2 (Neural Networks)}

\myhwtitle{1}{2(a)}{Gregory King}

\bigskip

\end{document}




